{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c705ccb2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "In this era of Artificial Intelligence, humans are becoming more dependent on technology. With the enhanced technology, multinational companies like Google, Tesla, Uber, Ford, Audi, Toyota, Mercedes-Benz, and many more are working on automating vehicles. They are trying to make more accurate autonomous or driverless vehicles. You all might know about self-driving cars, where the vehicle itself behaves like a driver and does not need any human guidance to run on the road. This is not wrong to think about the safety aspects—a chance of significant accidents from machines. But no machines are more accurate than humans. Researchers are running many algorithms to ensure 100% road safety and accuracy.\n",
    "\n",
    "When you go on the road, you see various traffic signs like traffic signals, turn left or right, speed limits, no passing of heavy vehicles, no entry, children crossing, etc., that you need to follow for a safe drive. Likewise, autonomous vehicles also have to interpret these signs and make decisions to achieve accuracy. The methodology of recognizing which class a traffic sign belongs to is called Traffic signs classification.\n",
    "\n",
    "In this Deep Learning project, we will build a model for the classification of traffic signs available in the image into many categories using a convolutional neural network(CNN) and Keras library.\n",
    "\n",
    "\n",
    "The image dataset is consists of more than 50,000 pictures of various traffic signs(speed limit, crossing, traffic signals, etc.) Around 43 different classes are present in the dataset for image classification. The dataset classes vary in size like some class has very few images while others have a vast number of images. The dataset doesn’t take much time and space to download as the file size is around 314.36 MB. It contains two separate folders, train and test, where the train folder is consists of classes, and every category contains various images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23fc3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow \n",
    "pip install tensorflow keras \n",
    "pip install tensorflow sklearn \n",
    "pip install tensorflow matplotlib \n",
    "pip install tensorflow pandas \n",
    "pip install tensorflow pil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525fe08f",
   "metadata": {},
   "source": [
    "* WorkFlow \n",
    "* WE need to follow foue steps to build our traffic sign classification model\n",
    "1. - Dataset Exploration \n",
    "2. - CNN Model Building\n",
    "3. - Model training and validation\n",
    "4. - Model Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d4e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "from PIL import Image\n",
    "import os \n",
    "from sklearn.model_selection\n",
    "import train_test_split \n",
    "from keras.utils import to_categorical \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3306e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "classes = 43 \n",
    "cur_path = os.getcwd() \n",
    "for i in range(classes): \n",
    "  path = os. path.join(cur_path,'train', str(i)) \n",
    "  images = os.listdir(path) \n",
    "  for a in images: \n",
    "     try: \n",
    "     image = Image.open(path + '\\'+ a) \n",
    "     image = image.resize((30,30)) \n",
    "     image = np.array(image) \n",
    "     data.append(image) \n",
    "     labels.append(i) \n",
    "   except: \n",
    "        print(\"Error loading image\") \n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d550d6",
   "metadata": {},
   "source": [
    "In the end, we have to store every image with its corresponding labels into lists.\n",
    "A NumPy array is needed to feed the data to the model, so we convert this list into an array.\n",
    "Now, the shape of our data is (39209, 30, 30, 3), where 39209 represents the number of images,\n",
    "30*30 represents the image sizes into pixels, \n",
    "and the last 3 represents the RGB value(availability of coloured data)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3105b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Print(data.shape, labels.shape)\n",
    "#Splitting training and testing dataset\n",
    "X_t1, X_t2, y_t1, y_t2 = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "print(X_t1.shape, X_t2.shape, y_t1.shape, y_t2.shape)\n",
    "\n",
    "#Converting the labels into one hot encoding\n",
    "y_t1 = to_categorical(y_t1, 43)\n",
    "y_t2 = to_categorical(y_t2, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b2c5a",
   "metadata": {},
   "source": [
    "# CNN Model Building\n",
    "* We build a model to classify the image into their respective catogories\n",
    "* The Architecture of our model is\n",
    "\n",
    "* 2 Conv2D layer (filter=32, kernel_size=(5,5), activation=”relu”)\n",
    "\n",
    "* MaxPool2D layer ( pool_size=(2,2))\n",
    "\n",
    "* Dropout layer (rate=0.25)\n",
    "\n",
    "* 2 Conv2D layer (filter=64, kernel_size=(3,3), activation=”relu”)\n",
    "\n",
    "* MaxPool2D layer ( pool_size=(2,2))\n",
    "\n",
    "* Dropout layer (rate=0.25)\n",
    "\n",
    "* Dense Fully connected layer (256 nodes, activation=”relu”)\n",
    "\n",
    "* Dropout layer (rate=0.5)\n",
    "* Dense layer (43 nodes, activation=” softmax”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc965fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(43, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feb91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilation of the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1278ab1",
   "metadata": {},
   "source": [
    "# Model Trainning and Validation\n",
    "* To train our model, we will use the model.fit() method that works well after the successful building of model architecture. With the help of 64 batch sizes, we got 95%accuracy on training sets and acquired stability after 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4357c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 15\n",
    "anc = model.fit(X_t1, y_t1, batch_size=32, epochs=eps, validation_data=(X_t2, y_t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c076cabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------Plotting graphs for accuracy\n",
    "plt.figure(0)\n",
    "plt.plot(anc.anc['accuracy'], label='training accuracy')\n",
    "plt.plot(anc.anc['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34064489",
   "metadata": {},
   "source": [
    "## MOdel Testing\n",
    "* A  folder named” test” is available in our dataset; inside that, we got the main working comma-separated file called” test.csv”. It comprises two things, the image paths, and their respective class labels. We can use the pandas’ python library to extract the image path with corresponding labels. Next, we need to resize our images to 30×30 pixels to predict the model and create a numpy array filled with image data. To understand how the model predicts the actual labels, we need to import accuracy_score from the sklearn.metrics. At last, we are calling the Keras model.save() method to keep our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415fc595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------>>>>> testing accuracy on test dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_test = pd.read_csv('Test.csv')\n",
    "labels = y_test[\"ClassId\"].values\n",
    "imgs = y_test[\"Path\"].values\n",
    "data=[]\n",
    "for img in imgs:\n",
    "   image = Image.open(img)\n",
    "   image = image.resize((30,30))\n",
    "   data.append(np.array(image))\n",
    "X_test=np.array(data)\n",
    "pred = model.predict_classes(X_test)\n",
    "\n",
    "#Accuracy with the test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(labels, pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db69ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(‘traffic_classifier.h5’)\n",
    "#to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3558c840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "import numpy\n",
    "#load the trained model to classify sign\n",
    "from keras.models import load_model\n",
    "model = load_model('traffic_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e416baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dictionary to label all traffic signs class.\n",
    "classes = { 1:'Speed limit (20km/h)',\n",
    "           2:'Speed limit (30km/h)',\n",
    "           3:'Speed limit (50km/h)',\n",
    "           4:'Speed limit (60km/h)',\n",
    "           5:'Speed limit (70km/h)',\n",
    "           6:'Speed limit (80km/h)',\n",
    "           7:'End of speed limit (80km/h)',\n",
    "           8:'Speed limit (100km/h)',\n",
    "           9:'Speed limit (120km/h)',\n",
    "           10:'No passing',\n",
    "           11:'No passing veh over 3.5 tons',\n",
    "           12:'Right-of-way at intersection',\n",
    "           13:'Priority road',\n",
    "           14:'Yield',\n",
    "           15:'Stop',\n",
    "           16:'No vehicles',\n",
    "           17:'Veh > 3.5 tons prohibited',\n",
    "           18:'No entry',\n",
    "           19:'General caution',\n",
    "           20:'Dangerous curve left',\n",
    "           21:'Dangerous curve right',\n",
    "           22:'Double curve',\n",
    "           23:'Bumpy road',\n",
    "           24:'Slippery road',\n",
    "           25:'Road narrows on the right',\n",
    "           26:'Road work',\n",
    "           27:'Traffic signals',\n",
    "           28:'Pedestrians',\n",
    "           29:'Children crossing',\n",
    "           30:'Bicycles crossing',\n",
    "           31:'Beware of ice/snow',\n",
    "           32:'Wild animals crossing',\n",
    "           33:'End speed + passing limits',\n",
    "           34:'Turn right ahead',\n",
    "           35:'Turn left ahead',\n",
    "           36:'Ahead only',\n",
    "           37:'Go straight or right',\n",
    "           38:'Go straight or left',\n",
    "           39:'Keep right',\n",
    "           40:'Keep left',\n",
    "           41:'Roundabout mandatory',\n",
    "           42:'End of no passing',\n",
    "           43:'End no passing vehicle with a weight greater than 3.5 tons' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0618a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialise GUI\n",
    "top=tk.Tk()\n",
    "top.geometry('800x600')\n",
    "top.title('Traffic sign classification')\n",
    "top.configure(background='#CDCDCD')\n",
    "label=Label(top,background='#CDCDCD', font=('arial',15,'bold'))\n",
    "sign_image = Label(top)\n",
    "def classify(file_path):\n",
    "   global label_packed\n",
    "   image = Image.open(file_path)\n",
    "   image = image.resize((30,30))\n",
    "   image = numpy.expand_dims(image, axis=0)\n",
    "   image = numpy.array(image)\n",
    "   pred = model.predict_classes([image])[0]\n",
    "   sign = classes[pred+1]\n",
    "   print(sign)\n",
    "   label.configure(foreground='#011638', text=sign)\n",
    "def show_classify_button(file_path):\n",
    "   classify_b=Button(top,text=\"Classify Image\",command=lambda: classify(file_path),padx=10,pady=5)\n",
    "   classify_b.configure(background='#364156', foreground='white',font=('arial',10,'bold'))\n",
    "   classify_b.place(relx=0.79,rely=0.46)\n",
    "def upload_image():\n",
    "try:\n",
    "       file_path=filedialog.askopenfilename()\n",
    "       uploaded=Image.open(file_path)\n",
    "       uploaded.thumbnail(((top.winfo_width()/2.25),(top.winfo_height()/2.25)))\n",
    "       im=ImageTk.PhotoImage(uploaded)\n",
    "       sign_image.configure(image=im)\n",
    "       sign_image.image=im\n",
    "       label.configure(text='')\n",
    "       show_classify_button(file_path)\n",
    "except:\n",
    "       pass\n",
    "upload=Button(top,text=\"Upload an image\",command=upload_image,padx=10,pady=5)\n",
    "upload.configure(background='#364156', foreground='white',font=('arial',10,'bold'))\n",
    "upload.pack(side=BOTTOM,pady=50)\n",
    "sign_image.pack(side=BOTTOM,expand=True)\n",
    "label.pack(side=BOTTOM,expand=True)\n",
    "heading = Label(top, text=\"check traffic sign\",pady=20, font=('arial',20,'bold'))\n",
    "heading.configure(background='#CDCDCD',foreground='#364156')\n",
    "heading.pack()\n",
    "top.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98e464c",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "* In this Notebook, we created a CNN model to identify traffic signs and classify them with 95% accuracy. We had observed the accuracy and loss changes over a large dataset. GUI of this model makes it easy to understand how signs are classified into several classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df19d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b904a41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3095ccf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80775cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d56268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a4ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8248fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b7b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a0d347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f64461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6378dc09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a5130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6194e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fba7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16373fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f297262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a773c238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ce0462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae500d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9037476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d086de55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cff6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0cf92a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd049a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b4703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be769f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1472f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c7dd03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
